---
layout: post
title: Blog Post 6
---

In this Blog Post, we will develop and assess a fake news classifier using Tensorflow.

#### Data Source
Our data for this assignment comes from the article

- Ahmed H, Traore I, Saad S. (2017) “Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques. In: Traore I., Woungang I., Awad A. (eds) Intelligent, Secure, and Dependable Systems in Distributed and Cloud Environments. ISDDC 2017. Lecture Notes in Computer Science, vol 10618. Springer, Cham (pp. 127-138).

Prof.Chodrow accessed it from [Kaggle](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset). He has done a small amount of data cleaning, and performed a train-test split. We will use the his version of data.

## §1. Acquire Training Data

We will start be creating a block of code that will hold our import statements.


```python
#importing packages 
import numpy as np
import pandas as pd
import tensorflow as tf
import re
import string
import matplotlib.pyplot as plt

from tensorflow.keras import layers
from tensorflow.keras import losses
from tensorflow import keras

from tensorflow.keras.layers.experimental.preprocessing import TextVectorization
from tensorflow.keras.layers.experimental.preprocessing import StringLookup

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
```

Now let's access the training data provided by Prof. Chodrow.


```python
train_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true"
train_set = pd.read_csv(train_url)
```


```python
train_set.head(10)
```





  <div id="df-d6a7e7f9-4276-4738-9d13-20fb276c19ad">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>title</th>
      <th>text</th>
      <th>fake</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17366</td>
      <td>Merkel: Strong result for Austria's FPO 'big c...</td>
      <td>German Chancellor Angela Merkel said on Monday...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5634</td>
      <td>Trump says Pence will lead voter fraud panel</td>
      <td>WEST PALM BEACH, Fla.President Donald Trump sa...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17487</td>
      <td>JUST IN: SUSPECTED LEAKER and “Close Confidant...</td>
      <td>On December 5, 2017, Circa s Sara Carter warne...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>12217</td>
      <td>Thyssenkrupp has offered help to Argentina ove...</td>
      <td>Germany s Thyssenkrupp, has offered assistance...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5535</td>
      <td>Trump say appeals court decision on travel ban...</td>
      <td>President Donald Trump on Thursday called the ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>13616</td>
      <td>North Korea says successfully launches new ICB...</td>
      <td>North Korea successfully launched a new type o...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1707</td>
      <td>California lawmakers take anti-Trump stance as...</td>
      <td>SACRAMENTO, Calif.California lawmakers voted t...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>15299</td>
      <td>New Delhi declares emergency as toxic smog thi...</td>
      <td>NEW The Indian capital declared a pollution em...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>4049</td>
      <td>AUDIO: Hannity Has RACIST Meltdown, Wants To ...</td>
      <td>Nobody would have ever said this about any of ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9</th>
      <td>12166</td>
      <td>Forgetful ministers keep Mugabe's name alive a...</td>
      <td>Zimbabwe s Robert Mugabe may have been deposed...</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-d6a7e7f9-4276-4738-9d13-20fb276c19ad')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-d6a7e7f9-4276-4738-9d13-20fb276c19ad button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-d6a7e7f9-4276-4738-9d13-20fb276c19ad');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>




Take a look at this data. We can tell each row of the data corresponds to an article. The title column gives the title of the article, while the text column gives the full article text. The final column, called fake, is `0` if the article is true and `1` if the article contains fake news, as determined by the authors of the paper above.

## §2. Make a Dataset

TensorFlow Dataset has a special `Dataset` class that's easy to organize when writing data pipelines.

In this section, we want to write a function called `make_dataset` to construct our Datasetthat has all the stopwrods removed from text and title and takes two inputs `text` and `title` of the form `("title", "text")`. We will batch our dataset. Batching causes our model to train on chunks of data rather than individual rows. This can sometimes reduce accuracy, but can also greatly increase the speed of training. Finding a balance is key. batches of 100 rows to work well.


```python
# define stopwords 
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')
stop = stopwords.words('english')
```

    [nltk_data] Downloading package stopwords to /root/nltk_data...
    [nltk_data]   Package stopwords is already up-to-date!
    


```python
def make_dataset(df):
  # remove stopwords from text and title
  df = df[['text','title', "fake"]].apply(lambda x: [item for item in x if item not in stop])
  # construct tf dataset
  # construct dataset from a tuple of dictionaries
  # the first dictionary is the inputs 
  # the second dictionary specifies the output
  data = tf.data.Dataset.from_tensor_slices(
      ({
          "title" : df[["title"]],
          "text"  : df[["text"]]
      },
       {
           "fake" : df[["fake"]]
        }))

  # batch the dataset to increase the speed of training
  data = data.batch(100)
  
  return data
```

Now, we call the function `make_dataset` on the training dataframe to produce a `Dataset`.


```python
Dataset = make_dataset(train_set)
```

### Validation Data

Next, we are going to perform a train/validation split.We will split of 20% of the training set to use for validation.


```python
Dataset = Dataset.shuffle(buffer_size = len(Dataset))

train_size = int(0.8*len(Dataset))

train = Dataset.take(train_size)
val   = Dataset.skip(train_size)

len(train), len(val)
```




    (180, 45)



### Base Rate

The base rate refers to the accuracy of a model that always makes the same guess. We will determine the base rate for this data set by examining the labels on the training set to see the proportion of the most frequent label.

We would like to compute the number of rows in our training data with label 0 (true news) and label 1 (fake news). Why do we care about this? We need to know the most frequent label since our baseline machine learning model is likely to guess that label!



```python
train_set.groupby("fake").size()
```




    fake
    0    10709
    1    11740
    dtype: int64



`1` is more frequent than `0`. We can then calculate the base rate:


```python
train_set["fake"].mean()
```




    0.522963160942581



Our base rate is 52.29%.

## §3. Create Models

We will use TensorFlow models to offer a perspective on the following question:

**When detecting fake news, is it most effective to focus on only the title of the article, the full text of the article, or both?**

Before building our models, we will first standarize our data.


```python
##Data Prep: Vectorizing our Data
#Does frequency of capitalization and punctuation give indication for authenticity of article?
size_vocabulary = 2000
def standardization(input_data):
    lowercase = tf.strings.lower(input_data)
    no_punctuation = tf.strings.regex_replace(lowercase,
                                  '[%s]' % re.escape(string.punctuation),'')
    return no_punctuation 

vectorize_layer = TextVectorization(
    standardize=standardization,
    max_tokens=size_vocabulary, # only consider this many words
    output_mode='int',
  ) 
```

We need to adapt the vectorization layer to the titles. In the adaptation process, the vectorization layer learns what words are common in the title.


```python
vectorize_layer.adapt(train.map(lambda x, y: x['title']))
```

We will create a share embbedding layer for the models.


```python
# shared embedding layer

embedding = layers.Embedding(size_vocabulary, 3, name = "embedding")
```

### Model 1

In this model, we will only use the article `title` as an input. Since the title column contains just one entry for each piece of news, so the shape is (1,) (a tuple of length 1). 


```python
# input
title_input = keras.Input(
    shape = (1,), 
    name = "title",
    dtype = "string"
)
```


```python
# layers for processing the title, pretty much the same as from our lecture
# on text classification
title_features = vectorize_layer(title_input)
title_features = embedding(title_features)
title_features = layers.Dropout(0.2)(title_features)
title_features = layers.GlobalAveragePooling1D()(title_features)
title_features = layers.Dropout(0.2)(title_features)
title_features = layers.Dense(32, activation='relu')(title_features)
```


```python
output = layers.Dense(2, name = 'fake')(title_features)
```


```python
model1 = keras.Model(
    inputs = title_input,
    outputs = output
)
```

Let's visualize our first model.


```python
keras.utils.plot_model(model1)
```

![Blog-Post-6-Plot1.png](https://raw.githubusercontent.com/JadenWSR/JadenWSR.github.io/master/images/Blog-Post-6-Plot1.png)


```python
model1.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']
)
```


```python
model1_history = model1.fit(train, 
                    validation_data=val,
                    epochs = 50)
```

    Epoch 1/50
    

    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning: Input dict contained keys ['text'] which did not match any model input. They will be ignored by the model.
      inputs = self._flatten_to_reference_inputs(inputs)
    

    180/180 [==============================] - 5s 16ms/step - loss: 0.6217 - accuracy: 0.7398 - val_loss: 0.4686 - val_accuracy: 0.8904
    Epoch 2/50
    180/180 [==============================] - 2s 13ms/step - loss: 0.3739 - accuracy: 0.8633 - val_loss: 0.2600 - val_accuracy: 0.9193
    Epoch 3/50
    180/180 [==============================] - 3s 15ms/step - loss: 0.2497 - accuracy: 0.9094 - val_loss: 0.1892 - val_accuracy: 0.9351
    Epoch 4/50
    180/180 [==============================] - 3s 14ms/step - loss: 0.1987 - accuracy: 0.9301 - val_loss: 0.1525 - val_accuracy: 0.9444
    Epoch 5/50
    180/180 [==============================] - 3s 15ms/step - loss: 0.1668 - accuracy: 0.9414 - val_loss: 0.1309 - val_accuracy: 0.9518
    Epoch 6/50
    180/180 [==============================] - 2s 13ms/step - loss: 0.1533 - accuracy: 0.9441 - val_loss: 0.1079 - val_accuracy: 0.9643
    Epoch 7/50
    180/180 [==============================] - 3s 14ms/step - loss: 0.1418 - accuracy: 0.9469 - val_loss: 0.1065 - val_accuracy: 0.9607
    Epoch 8/50
    180/180 [==============================] - 3s 15ms/step - loss: 0.1338 - accuracy: 0.9490 - val_loss: 0.1126 - val_accuracy: 0.9573
    Epoch 9/50
    180/180 [==============================] - 2s 12ms/step - loss: 0.1268 - accuracy: 0.9529 - val_loss: 0.1007 - val_accuracy: 0.9620
    Epoch 10/50
    180/180 [==============================] - 3s 14ms/step - loss: 0.1203 - accuracy: 0.9564 - val_loss: 0.0898 - val_accuracy: 0.9667
    Epoch 11/50
    180/180 [==============================] - 3s 14ms/step - loss: 0.1209 - accuracy: 0.9541 - val_loss: 0.0798 - val_accuracy: 0.9707
    Epoch 12/50
    180/180 [==============================] - 3s 15ms/step - loss: 0.1130 - accuracy: 0.9574 - val_loss: 0.0824 - val_accuracy: 0.9742
    Epoch 13/50
    180/180 [==============================] - 3s 13ms/step - loss: 0.1094 - accuracy: 0.9596 - val_loss: 0.0772 - val_accuracy: 0.9753
    Epoch 14/50
    180/180 [==============================] - 2s 13ms/step - loss: 0.1094 - accuracy: 0.9592 - val_loss: 0.0823 - val_accuracy: 0.9702
    Epoch 15/50
    180/180 [==============================] - 2s 13ms/step - loss: 0.1026 - accuracy: 0.9619 - val_loss: 0.0704 - val_accuracy: 0.9729
    Epoch 16/50
    180/180 [==============================] - 3s 14ms/step - loss: 0.1062 - accuracy: 0.9591 - val_loss: 0.0690 - val_accuracy: 0.9744
    Epoch 17/50
    180/180 [==============================] - 2s 13ms/step - loss: 0.1033 - accuracy: 0.9602 - val_loss: 0.0687 - val_accuracy: 0.9744
    Epoch 18/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.1002 - accuracy: 0.9612 - val_loss: 0.0695 - val_accuracy: 0.9776
    Epoch 19/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.1015 - accuracy: 0.9621 - val_loss: 0.0730 - val_accuracy: 0.9738
    Epoch 20/50
    180/180 [==============================] - 1s 8ms/step - loss: 0.0984 - accuracy: 0.9630 - val_loss: 0.0723 - val_accuracy: 0.9742
    Epoch 21/50
    180/180 [==============================] - 1s 8ms/step - loss: 0.0981 - accuracy: 0.9617 - val_loss: 0.0623 - val_accuracy: 0.9778
    Epoch 22/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0968 - accuracy: 0.9627 - val_loss: 0.0639 - val_accuracy: 0.9778
    Epoch 23/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0945 - accuracy: 0.9622 - val_loss: 0.0639 - val_accuracy: 0.9773
    Epoch 24/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0930 - accuracy: 0.9663 - val_loss: 0.0793 - val_accuracy: 0.9713
    Epoch 25/50
    180/180 [==============================] - 1s 8ms/step - loss: 0.0958 - accuracy: 0.9627 - val_loss: 0.0656 - val_accuracy: 0.9780
    Epoch 26/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0937 - accuracy: 0.9645 - val_loss: 0.0546 - val_accuracy: 0.9811
    Epoch 27/50
    180/180 [==============================] - 2s 13ms/step - loss: 0.0949 - accuracy: 0.9618 - val_loss: 0.0585 - val_accuracy: 0.9807
    Epoch 28/50
    180/180 [==============================] - 2s 12ms/step - loss: 0.0920 - accuracy: 0.9638 - val_loss: 0.0605 - val_accuracy: 0.9782
    Epoch 29/50
    180/180 [==============================] - 3s 14ms/step - loss: 0.0878 - accuracy: 0.9657 - val_loss: 0.0679 - val_accuracy: 0.9751
    Epoch 30/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0923 - accuracy: 0.9636 - val_loss: 0.0559 - val_accuracy: 0.9807
    Epoch 31/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0888 - accuracy: 0.9638 - val_loss: 0.0688 - val_accuracy: 0.9739
    Epoch 32/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0914 - accuracy: 0.9651 - val_loss: 0.0607 - val_accuracy: 0.9773
    Epoch 33/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0878 - accuracy: 0.9647 - val_loss: 0.0694 - val_accuracy: 0.9747
    Epoch 34/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0911 - accuracy: 0.9645 - val_loss: 0.0510 - val_accuracy: 0.9820
    Epoch 35/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0913 - accuracy: 0.9642 - val_loss: 0.0609 - val_accuracy: 0.9804
    Epoch 36/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0882 - accuracy: 0.9669 - val_loss: 0.0593 - val_accuracy: 0.9804
    Epoch 37/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0921 - accuracy: 0.9638 - val_loss: 0.0566 - val_accuracy: 0.9780
    Epoch 38/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0908 - accuracy: 0.9638 - val_loss: 0.0620 - val_accuracy: 0.9776
    Epoch 39/50
    180/180 [==============================] - 2s 13ms/step - loss: 0.0865 - accuracy: 0.9657 - val_loss: 0.0548 - val_accuracy: 0.9796
    Epoch 40/50
    180/180 [==============================] - 3s 14ms/step - loss: 0.0876 - accuracy: 0.9655 - val_loss: 0.0606 - val_accuracy: 0.9782
    Epoch 41/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0918 - accuracy: 0.9635 - val_loss: 0.0592 - val_accuracy: 0.9780
    Epoch 42/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0914 - accuracy: 0.9633 - val_loss: 0.0537 - val_accuracy: 0.9775
    Epoch 43/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0890 - accuracy: 0.9652 - val_loss: 0.0570 - val_accuracy: 0.9809
    Epoch 44/50
    180/180 [==============================] - 2s 9ms/step - loss: 0.0901 - accuracy: 0.9632 - val_loss: 0.0551 - val_accuracy: 0.9827
    Epoch 45/50
    180/180 [==============================] - 3s 15ms/step - loss: 0.0892 - accuracy: 0.9644 - val_loss: 0.0613 - val_accuracy: 0.9791
    Epoch 46/50
    180/180 [==============================] - 3s 16ms/step - loss: 0.0878 - accuracy: 0.9643 - val_loss: 0.0547 - val_accuracy: 0.9822
    Epoch 47/50
    180/180 [==============================] - 3s 15ms/step - loss: 0.0862 - accuracy: 0.9663 - val_loss: 0.0649 - val_accuracy: 0.9784
    Epoch 48/50
    180/180 [==============================] - 2s 11ms/step - loss: 0.0853 - accuracy: 0.9660 - val_loss: 0.0590 - val_accuracy: 0.9747
    Epoch 49/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0880 - accuracy: 0.9645 - val_loss: 0.0553 - val_accuracy: 0.9793
    Epoch 50/50
    180/180 [==============================] - 2s 8ms/step - loss: 0.0875 - accuracy: 0.9646 - val_loss: 0.0554 - val_accuracy: 0.9827
    


```python
def visualize_history(history, baseline):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']

    loss = history.history['loss']
    val_loss = history.history['val_loss']

    plt.figure(figsize=(8, 8))
    plt.subplot(2, 1, 1)
    plt.plot(acc, label='Training Accuracy')
    plt.plot(val_acc, label='Validation Accuracy')
    plt.axhline(y= baseline, color='black', label='Baseline accuracy = {m}%'.format(m=round(baseline*100, 1)))
    plt.legend(loc='lower right')
    plt.ylabel('Accuracy')
    plt.ylim([min(plt.ylim()),1])
    plt.title('Training and Validation Accuracy')

    plt.subplot(2, 1, 2)
    plt.plot(loss, label='Training Loss')
    plt.plot(val_loss, label='Validation Loss')
    plt.legend(loc='upper right')
    plt.ylabel('Cross Entropy')
    plt.ylim([0,1.0])
    plt.title('Training and Validation Loss')
    plt.xlabel('epoch')
    plt.show()
```


```python
visualize_history(model1_history, 0.5229)
```

![Blog-Post-6-Plot2.png](https://raw.githubusercontent.com/JadenWSR/JadenWSR.github.io/master/images/Blog-Post-6-Plot2.png)


```python
model1.evaluate(val)
```

    45/45 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.9773
    




    [0.06247315928339958, 0.9772982597351074]



It seems that our title model can accurately assess whether or not an article is fake about **97.73%** of the time! That is pretty impressive!

### Model 2

In this model, we will only use the article `text` as an input. Since the text column contains just one entry for each piece of news, so the shape is (1,) (a tuple of length 1). 


```python
# input
text_input = keras.Input(
    shape = (1,), 
    name = "text",
    dtype = "string"
)
```


```python
# layers for processing the text, pretty much the same as from our lecture
# on text classification
text_features = vectorize_layer(text_input)
text_features = embedding(text_features)
text_features = layers.Dropout(0.2)(text_features)
text_features = layers.GlobalAveragePooling1D()(text_features)
text_features = layers.Dropout(0.2)(text_features)
text_features = layers.Dense(32, activation='relu')(text_features)
```


```python
output = layers.Dense(2, name = 'fake')(text_features)
```


```python
model2 = keras.Model(
    inputs = text_input,
    outputs = output
)
```

Let's visualize our text model.


```python
keras.utils.plot_model(model2)
```

![Blog-Post-6-Plot3.png](https://raw.githubusercontent.com/JadenWSR/JadenWSR.github.io/master/images/Blog-Post-6-Plot3.png)


```python
model2.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']
)
```


```python
model2_history = model2.fit(train, 
                    validation_data=val,
                    epochs = 50)
```

    Epoch 1/50
    

    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning: Input dict contained keys ['title'] which did not match any model input. They will be ignored by the model.
      inputs = self._flatten_to_reference_inputs(inputs)
    

    180/180 [==============================] - 6s 27ms/step - loss: 0.6783 - accuracy: 0.6722 - val_loss: 0.6520 - val_accuracy: 0.8589
    Epoch 2/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.5837 - accuracy: 0.8402 - val_loss: 0.4938 - val_accuracy: 0.9204
    Epoch 3/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.4234 - accuracy: 0.8987 - val_loss: 0.3436 - val_accuracy: 0.9202
    Epoch 4/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.3206 - accuracy: 0.9251 - val_loss: 0.2570 - val_accuracy: 0.9493
    Epoch 5/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.2584 - accuracy: 0.9355 - val_loss: 0.2285 - val_accuracy: 0.9542
    Epoch 6/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.2249 - accuracy: 0.9424 - val_loss: 0.2051 - val_accuracy: 0.9564
    Epoch 7/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.2031 - accuracy: 0.9507 - val_loss: 0.1796 - val_accuracy: 0.9620
    Epoch 8/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.1894 - accuracy: 0.9519 - val_loss: 0.1528 - val_accuracy: 0.9627
    Epoch 9/50
    180/180 [==============================] - 5s 26ms/step - loss: 0.1741 - accuracy: 0.9543 - val_loss: 0.1614 - val_accuracy: 0.9562
    Epoch 10/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.1683 - accuracy: 0.9525 - val_loss: 0.1336 - val_accuracy: 0.9551
    Epoch 11/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.1564 - accuracy: 0.9606 - val_loss: 0.1376 - val_accuracy: 0.9473
    Epoch 12/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.1520 - accuracy: 0.9596 - val_loss: 0.1406 - val_accuracy: 0.9611
    Epoch 13/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.1495 - accuracy: 0.9574 - val_loss: 0.1199 - val_accuracy: 0.9738
    Epoch 14/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.1427 - accuracy: 0.9628 - val_loss: 0.1093 - val_accuracy: 0.9749
    Epoch 15/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.1362 - accuracy: 0.9622 - val_loss: 0.1114 - val_accuracy: 0.9729
    Epoch 16/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.1304 - accuracy: 0.9657 - val_loss: 0.1065 - val_accuracy: 0.9738
    Epoch 17/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.1246 - accuracy: 0.9679 - val_loss: 0.1172 - val_accuracy: 0.9742
    Epoch 18/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.1262 - accuracy: 0.9640 - val_loss: 0.1096 - val_accuracy: 0.9753
    Epoch 19/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.1171 - accuracy: 0.9676 - val_loss: 0.1036 - val_accuracy: 0.9689
    Epoch 20/50
    180/180 [==============================] - 5s 29ms/step - loss: 0.1145 - accuracy: 0.9672 - val_loss: 0.0967 - val_accuracy: 0.9771
    Epoch 21/50
    180/180 [==============================] - 4s 23ms/step - loss: 0.1115 - accuracy: 0.9676 - val_loss: 0.0983 - val_accuracy: 0.9800
    Epoch 22/50
    180/180 [==============================] - 4s 23ms/step - loss: 0.1101 - accuracy: 0.9684 - val_loss: 0.0986 - val_accuracy: 0.9773
    Epoch 23/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.1075 - accuracy: 0.9697 - val_loss: 0.0976 - val_accuracy: 0.9742
    Epoch 24/50
    180/180 [==============================] - 5s 30ms/step - loss: 0.1047 - accuracy: 0.9692 - val_loss: 0.0781 - val_accuracy: 0.9793
    Epoch 25/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.1039 - accuracy: 0.9713 - val_loss: 0.0796 - val_accuracy: 0.9802
    Epoch 26/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0965 - accuracy: 0.9727 - val_loss: 0.0786 - val_accuracy: 0.9809
    Epoch 27/50
    180/180 [==============================] - 4s 23ms/step - loss: 0.1009 - accuracy: 0.9728 - val_loss: 0.0850 - val_accuracy: 0.9747
    Epoch 28/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0949 - accuracy: 0.9724 - val_loss: 0.0811 - val_accuracy: 0.9818
    Epoch 29/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0969 - accuracy: 0.9718 - val_loss: 0.0706 - val_accuracy: 0.9849
    Epoch 30/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0911 - accuracy: 0.9728 - val_loss: 0.0656 - val_accuracy: 0.9867
    Epoch 31/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0942 - accuracy: 0.9725 - val_loss: 0.0749 - val_accuracy: 0.9809
    Epoch 32/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0898 - accuracy: 0.9748 - val_loss: 0.0905 - val_accuracy: 0.9696
    Epoch 33/50
    180/180 [==============================] - 4s 23ms/step - loss: 0.0917 - accuracy: 0.9720 - val_loss: 0.0776 - val_accuracy: 0.9811
    Epoch 34/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0871 - accuracy: 0.9738 - val_loss: 0.0646 - val_accuracy: 0.9838
    Epoch 35/50
    180/180 [==============================] - 4s 23ms/step - loss: 0.0856 - accuracy: 0.9738 - val_loss: 0.0768 - val_accuracy: 0.9827
    Epoch 36/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0856 - accuracy: 0.9753 - val_loss: 0.0663 - val_accuracy: 0.9838
    Epoch 37/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0870 - accuracy: 0.9743 - val_loss: 0.0640 - val_accuracy: 0.9827
    Epoch 38/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0833 - accuracy: 0.9735 - val_loss: 0.0591 - val_accuracy: 0.9852
    Epoch 39/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0813 - accuracy: 0.9733 - val_loss: 0.0627 - val_accuracy: 0.9856
    Epoch 40/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0811 - accuracy: 0.9762 - val_loss: 0.0698 - val_accuracy: 0.9844
    Epoch 41/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0746 - accuracy: 0.9771 - val_loss: 0.0554 - val_accuracy: 0.9882
    Epoch 42/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0759 - accuracy: 0.9771 - val_loss: 0.0590 - val_accuracy: 0.9822
    Epoch 43/50
    180/180 [==============================] - 4s 23ms/step - loss: 0.0811 - accuracy: 0.9740 - val_loss: 0.0622 - val_accuracy: 0.9851
    Epoch 44/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0767 - accuracy: 0.9760 - val_loss: 0.0650 - val_accuracy: 0.9862
    Epoch 45/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0766 - accuracy: 0.9756 - val_loss: 0.0632 - val_accuracy: 0.9860
    Epoch 46/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0807 - accuracy: 0.9736 - val_loss: 0.0476 - val_accuracy: 0.9882
    Epoch 47/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0733 - accuracy: 0.9786 - val_loss: 0.0627 - val_accuracy: 0.9840
    Epoch 48/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0714 - accuracy: 0.9757 - val_loss: 0.0620 - val_accuracy: 0.9873
    Epoch 49/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0684 - accuracy: 0.9792 - val_loss: 0.0564 - val_accuracy: 0.9858
    Epoch 50/50
    180/180 [==============================] - 4s 22ms/step - loss: 0.0700 - accuracy: 0.9783 - val_loss: 0.0567 - val_accuracy: 0.9838
    


```python
visualize_history(model2_history, 0.5229)
```

![Blog-Post-6-Plot4.png](https://raw.githubusercontent.com/JadenWSR/JadenWSR.github.io/master/images/Blog-Post-6-Plot4.png)


```python
model2.evaluate(val)
```

    45/45 [==============================] - 1s 13ms/step - loss: 0.0525 - accuracy: 0.9849
    




    [0.05247829854488373, 0.9848889112472534]



Similar as model1, it seems that our text model can accurately assess whether or not an article is fake about **98.49%** of the time! Model2 is doing slightly better than model1.

### Model 3

In this model, we will both the article title and the article text as input.

Let’s first shuffle our original data so that our model is not able to learn from prior data.


```python
## Creating a new Dataset to work with!
dataset = Dataset.shuffle(buffer_size = len(Dataset))

train_size = int(0.8 *len(dataset))
val_size = int(0.2 * len(dataset))

train_2 = dataset.take(train_size) 
val_2 = dataset.skip(train_size).take(val_size)
```

Here's simultaneously the most important and most boring part of the whole model: we are going to `concatenate` the output of the `title` pipeline with the output of the `text` pipeline:


```python
main = layers.concatenate([title_features, text_features], axis = 1)
```

Finally, let's pass the consolidated set of computed features through a few more Dense layers. Remember that the very last Dense layer should have a number of outputs equal to the number of classes in the data.

Observe that the output layer has a name, and that this name matches the key corresponding to the target data in the Datasets we will pass to the model. This is how TensorFlow knows which part of our data set to compare against the outputs!


```python
main = layers.Dense(32, activation='relu')(main)
output = layers.Dense(2, name = "fake")(main)
```


```python
model3 = keras.Model(
    inputs = [title_input, text_input],
    outputs = output
)
```

Let's visualize our third model.


```python
keras.utils.plot_model(model3)
```


![Blog-Post-6-Plot5.png](https://raw.githubusercontent.com/JadenWSR/JadenWSR.github.io/master/images/Blog-Post-6-Plot5.png)


```python
model3.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']
)
```


```python
model3_history = model3.fit(train_2, 
                    validation_data=val_2,
                    epochs = 70)
```

    Epoch 1/70
    180/180 [==============================] - 6s 25ms/step - loss: 0.1753 - accuracy: 0.9530 - val_loss: 0.0578 - val_accuracy: 0.9807
    Epoch 2/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0583 - accuracy: 0.9816 - val_loss: 0.0342 - val_accuracy: 0.9891
    Epoch 3/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0496 - accuracy: 0.9828 - val_loss: 0.0312 - val_accuracy: 0.9902
    Epoch 4/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0441 - accuracy: 0.9851 - val_loss: 0.0314 - val_accuracy: 0.9907
    Epoch 5/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0459 - accuracy: 0.9851 - val_loss: 0.0354 - val_accuracy: 0.9881
    Epoch 6/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0437 - accuracy: 0.9861 - val_loss: 0.0272 - val_accuracy: 0.9897
    Epoch 7/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0424 - accuracy: 0.9853 - val_loss: 0.0312 - val_accuracy: 0.9907
    Epoch 8/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0403 - accuracy: 0.9867 - val_loss: 0.0204 - val_accuracy: 0.9947
    Epoch 9/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0423 - accuracy: 0.9851 - val_loss: 0.0254 - val_accuracy: 0.9918
    Epoch 10/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0370 - accuracy: 0.9874 - val_loss: 0.0245 - val_accuracy: 0.9928
    Epoch 11/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0365 - accuracy: 0.9884 - val_loss: 0.0203 - val_accuracy: 0.9922
    Epoch 12/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0347 - accuracy: 0.9882 - val_loss: 0.0231 - val_accuracy: 0.9933
    Epoch 13/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0349 - accuracy: 0.9883 - val_loss: 0.0261 - val_accuracy: 0.9920
    Epoch 14/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0374 - accuracy: 0.9871 - val_loss: 0.0209 - val_accuracy: 0.9956
    Epoch 15/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0381 - accuracy: 0.9862 - val_loss: 0.0181 - val_accuracy: 0.9944
    Epoch 16/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0318 - accuracy: 0.9887 - val_loss: 0.0179 - val_accuracy: 0.9946
    Epoch 17/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0347 - accuracy: 0.9884 - val_loss: 0.0156 - val_accuracy: 0.9949
    Epoch 18/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0325 - accuracy: 0.9877 - val_loss: 0.0188 - val_accuracy: 0.9940
    Epoch 19/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0313 - accuracy: 0.9890 - val_loss: 0.0215 - val_accuracy: 0.9921
    Epoch 20/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0296 - accuracy: 0.9899 - val_loss: 0.0201 - val_accuracy: 0.9933
    Epoch 21/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0314 - accuracy: 0.9891 - val_loss: 0.0216 - val_accuracy: 0.9927
    Epoch 22/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0330 - accuracy: 0.9891 - val_loss: 0.0194 - val_accuracy: 0.9938
    Epoch 23/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0329 - accuracy: 0.9887 - val_loss: 0.0191 - val_accuracy: 0.9929
    Epoch 24/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 0.0236 - val_accuracy: 0.9918
    Epoch 25/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0275 - accuracy: 0.9904 - val_loss: 0.0181 - val_accuracy: 0.9937
    Epoch 26/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0309 - accuracy: 0.9895 - val_loss: 0.0159 - val_accuracy: 0.9951
    Epoch 27/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0264 - accuracy: 0.9911 - val_loss: 0.0128 - val_accuracy: 0.9958
    Epoch 28/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0295 - accuracy: 0.9903 - val_loss: 0.0143 - val_accuracy: 0.9967
    Epoch 29/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0276 - accuracy: 0.9908 - val_loss: 0.0157 - val_accuracy: 0.9947
    Epoch 30/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.0162 - val_accuracy: 0.9944
    Epoch 31/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.0232 - val_accuracy: 0.9931
    Epoch 32/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0284 - accuracy: 0.9899 - val_loss: 0.0203 - val_accuracy: 0.9942
    Epoch 33/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0255 - accuracy: 0.9920 - val_loss: 0.0127 - val_accuracy: 0.9953
    Epoch 34/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0283 - accuracy: 0.9904 - val_loss: 0.0129 - val_accuracy: 0.9971
    Epoch 35/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0243 - accuracy: 0.9914 - val_loss: 0.0166 - val_accuracy: 0.9947
    Epoch 36/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0275 - accuracy: 0.9898 - val_loss: 0.0161 - val_accuracy: 0.9949
    Epoch 37/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0224 - accuracy: 0.9918 - val_loss: 0.0143 - val_accuracy: 0.9962
    Epoch 38/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0257 - accuracy: 0.9908 - val_loss: 0.0120 - val_accuracy: 0.9969
    Epoch 39/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0233 - accuracy: 0.9918 - val_loss: 0.0130 - val_accuracy: 0.9960
    Epoch 40/70
    180/180 [==============================] - 5s 25ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.0114 - val_accuracy: 0.9960
    Epoch 41/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.0124 - val_accuracy: 0.9971
    Epoch 42/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0208 - accuracy: 0.9926 - val_loss: 0.0128 - val_accuracy: 0.9964
    Epoch 43/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0250 - accuracy: 0.9914 - val_loss: 0.0143 - val_accuracy: 0.9960
    Epoch 44/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.0088 - val_accuracy: 0.9973
    Epoch 45/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0232 - accuracy: 0.9915 - val_loss: 0.0098 - val_accuracy: 0.9973
    Epoch 46/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0222 - accuracy: 0.9922 - val_loss: 0.0143 - val_accuracy: 0.9964
    Epoch 47/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0222 - accuracy: 0.9919 - val_loss: 0.0128 - val_accuracy: 0.9955
    Epoch 48/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0207 - accuracy: 0.9934 - val_loss: 0.0227 - val_accuracy: 0.9929
    Epoch 49/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.0110 - val_accuracy: 0.9973
    Epoch 50/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0227 - accuracy: 0.9921 - val_loss: 0.0142 - val_accuracy: 0.9967
    Epoch 51/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0201 - accuracy: 0.9929 - val_loss: 0.0168 - val_accuracy: 0.9951
    Epoch 52/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 0.0145 - val_accuracy: 0.9956
    Epoch 53/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.0111 - val_accuracy: 0.9975
    Epoch 54/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.0064 - val_accuracy: 0.9989
    Epoch 55/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0199 - accuracy: 0.9926 - val_loss: 0.0086 - val_accuracy: 0.9980
    Epoch 56/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.0104 - val_accuracy: 0.9956
    Epoch 57/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0234 - accuracy: 0.9918 - val_loss: 0.0118 - val_accuracy: 0.9978
    Epoch 58/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0193 - accuracy: 0.9931 - val_loss: 0.0129 - val_accuracy: 0.9971
    Epoch 59/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.0104 - val_accuracy: 0.9964
    Epoch 60/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0188 - accuracy: 0.9933 - val_loss: 0.0107 - val_accuracy: 0.9967
    Epoch 61/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0198 - accuracy: 0.9931 - val_loss: 0.0102 - val_accuracy: 0.9978
    Epoch 62/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0225 - accuracy: 0.9922 - val_loss: 0.0103 - val_accuracy: 0.9969
    Epoch 63/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0186 - accuracy: 0.9931 - val_loss: 0.0102 - val_accuracy: 0.9982
    Epoch 64/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.0087 - val_accuracy: 0.9976
    Epoch 65/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.0064 - val_accuracy: 0.9980
    Epoch 66/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.0059 - val_accuracy: 0.9980
    Epoch 67/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0205 - accuracy: 0.9929 - val_loss: 0.0113 - val_accuracy: 0.9964
    Epoch 68/70
    180/180 [==============================] - 4s 24ms/step - loss: 0.0181 - accuracy: 0.9935 - val_loss: 0.0123 - val_accuracy: 0.9955
    Epoch 69/70
    180/180 [==============================] - 4s 25ms/step - loss: 0.0199 - accuracy: 0.9924 - val_loss: 0.0172 - val_accuracy: 0.9938
    Epoch 70/70
    180/180 [==============================] - 4s 25ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.0098 - val_accuracy: 0.9975
    


```python
visualize_history(model3_history, 0.5229)
```

![Blog-Post-6-Plot6.png](https://raw.githubusercontent.com/JadenWSR/JadenWSR.github.io/master/images/Blog-Post-6-Plot6.png)


```python
model3.evaluate(val)
```

    45/45 [==============================] - 1s 14ms/step - loss: 0.0068 - accuracy: 0.9982
    




    [0.00680549768730998, 0.9982222318649292]



It seems that our mixed model can accurately assess whether or not an article is fake about **99.82%** of the time! This is the best model among all 3 models.

## §4. Model Evaluation

By testing our model performance on on validation data, we have picked **model3**, the mixed model as our best model. Then, let's test our model performance on unseen test data. 

Let's read in and preprocess the test dataset.


```python
test_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_test.csv?raw=true"
test_set = pd.read_csv(test_url)
```

Take a look at our test data:


```python
test_set.head(10)
```





  <div id="df-385686b2-6ff2-44c0-981f-a16062de2ca2">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>title</th>
      <th>text</th>
      <th>fake</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>420</td>
      <td>CNN And MSNBC Destroy Trump, Black Out His Fa...</td>
      <td>Donald Trump practically does something to cri...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>14902</td>
      <td>Exclusive: Kremlin tells companies to deliver ...</td>
      <td>The Kremlin wants good news.  The Russian lead...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>322</td>
      <td>Golden State Warriors Coach Just WRECKED Trum...</td>
      <td>On Saturday, the man we re forced to call  Pre...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>16108</td>
      <td>Putin opens monument to Stalin's victims, diss...</td>
      <td>President Vladimir Putin inaugurated a monumen...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>10304</td>
      <td>BREAKING: DNC HACKER FIRED For Bank Fraud…Blam...</td>
      <td>Apparently breaking the law and scamming the g...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1873</td>
      <td>Trump, lawmakers agree on disaster aid, debt l...</td>
      <td>U.S. President Donald Trump and congressional ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>8577</td>
      <td>McConnell calls Army captain Khan 'an American...</td>
      <td>Senate Majority Leader Mitch McConnell, a Repu...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>12993</td>
      <td>Air strike reported near Somalia's capital, of...</td>
      <td>An air strike hit a village south of Somalia s...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>21793</td>
      <td>BALTIMORE POLICE UNION WANTS AN INDEPENDANT PR...</td>
      <td>The Police Union came out almost immediately a...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9</th>
      <td>17454</td>
      <td>TROLL CONGRESSWOMAN WANTS YOU TO SELL YOUR GUN...</td>
      <td>It s not for her to decide! We have the Second...</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-385686b2-6ff2-44c0-981f-a16062de2ca2')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-385686b2-6ff2-44c0-981f-a16062de2ca2 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-385686b2-6ff2-44c0-981f-a16062de2ca2');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
test = make_dataset(test_set)
```


```python
model3.evaluate(test)
```

    225/225 [==============================] - 7s 29ms/step - loss: 0.0651 - accuracy: 0.9833
    




    [0.0650782659649849, 0.9833400249481201]



If we used this model as a fake news detector, we would be right about **98.33%** of the time. Not bad!

## §5. Embedding Visualization

A word embedding refers to a representation of a word in a vector space. Each word is assigned an individual vector. The general aim of a word embedding is to create a representation such that words with related meanings are close to each other in a vector space, while words with different meanings are farther apart. One usually hopes for the directions connecting words to be meaningful as well.

Word embeddings are often produced as intermediate stages in many machine learning algorithms. In fact, we already made one -- it's the Embedding layer at the base of our model. Let's take a look at the embedding layer to see how our own model represents words in a vector space.

We chose to create a 3-dimensional embedding when constructing our model. This is fine for today, but state-of-the-art embeddings will typically have a much higher number of dimensions. For example, the Embedding Projector demo supplied by TensorFlow uses a default dimension of 200.


```python
weights = model3.get_layer('embedding').get_weights()[0] # get the weights from the embedding layer
vocab = vectorize_layer.get_vocabulary()                # get the vocabulary from our data prep for later
```


```python
weights
```




    array([[-1.19012012e-03, -1.86443608e-03,  5.70721895e-05],
           [-9.08479914e-02, -1.06032185e-01,  1.02904350e-01],
           [-4.69999723e-02, -2.33739950e-02,  1.03678256e-02],
           ...,
           [-2.67219281e+00, -2.67441988e+00,  2.71985936e+00],
           [ 9.47235227e-01,  1.05525899e+00, -9.80252922e-01],
           [-9.07754183e-01, -1.01780140e+00,  1.08219540e+00]], dtype=float32)



The collection of weights is 3-dimensional. For plotting in 2 dimensions, we have several choices for how to reduce the data to a 2d representation. A very simple and standard approach is our friend, principal component analysis (PCA).


```python
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
weights = pca.fit_transform(weights)
# Make a data frame from our results:
embedding_df = pd.DataFrame({
    'word' : vocab, 
    'x0'   : weights[:,0],
    'x1'   : weights[:,1]
})
```


```python
embedding_df
```





  <div id="df-6bba57c2-6843-4696-a3c3-9135ff4f7f29">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>word</th>
      <th>x0</th>
      <th>x1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td></td>
      <td>0.202498</td>
      <td>-0.005181</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[UNK]</td>
      <td>0.031107</td>
      <td>0.003748</td>
    </tr>
    <tr>
      <th>2</th>
      <td>to</td>
      <td>0.157942</td>
      <td>-0.031269</td>
    </tr>
    <tr>
      <th>3</th>
      <td>trump</td>
      <td>-0.122674</td>
      <td>-0.053198</td>
    </tr>
    <tr>
      <th>4</th>
      <td>in</td>
      <td>0.745727</td>
      <td>0.019837</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>deadline</td>
      <td>-0.051585</td>
      <td>0.061718</td>
    </tr>
    <tr>
      <th>1996</th>
      <td>damage</td>
      <td>1.552809</td>
      <td>-0.044488</td>
    </tr>
    <tr>
      <th>1997</th>
      <td>daily</td>
      <td>-4.452883</td>
      <td>-0.024606</td>
    </tr>
    <tr>
      <th>1998</th>
      <td>cuban</td>
      <td>1.926826</td>
      <td>-0.029043</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>cross</td>
      <td>-1.533392</td>
      <td>0.101418</td>
    </tr>
  </tbody>
</table>
<p>2000 rows × 3 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-6bba57c2-6843-4696-a3c3-9135ff4f7f29')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-6bba57c2-6843-4696-a3c3-9135ff4f7f29 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-6bba57c2-6843-4696-a3c3-9135ff4f7f29');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
import plotly.express as px
fig = px.scatter(embedding_df, 
                 x = "x0", 
                 y = "x1", 
                 size = list(np.ones(len(embedding_df))),
                 size_max = 5,
                 hover_name = "word")
fig.update_layout(plot_bgcolor="white")
fig.show()
```

{% include Blog-Post-6-Plot7.html %}

Cool, we made a word embedding! This embedding seems to have learned some reasonable associations. For example, inspection the plot by eye,we see that words like "shot", "destroy", and "lynch" are relatively close to each other. So are "voting", "Wall", and "donors", as well as "fired", "leaving", and "considering." Let's take a closer look. It seems that words in the direction towards the bottom right of the visualization have to do with politics and international situation. We can see this due to the mentions of “turkeys”,”capital”, “ireland”, "macron" and "zimbabwe".


```python
#getting a closer look at specific regions in our 2D representation
embedding_df[(embedding_df['x0'] > 3) & (embedding_df['x0'] < 5) & (embedding_df['x1'] < 0)]
```





  <div id="df-3bc0e5d6-53d8-4afb-8319-1fc2b935d1c1">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>word</th>
      <th>x0</th>
      <th>x1</th>
      <th>highlight</th>
      <th>size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>130</th>
      <td>twitter</td>
      <td>4.050928</td>
      <td>-0.027451</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>361</th>
      <td>said</td>
      <td>4.437564</td>
      <td>-0.008937</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>478</th>
      <td>macron</td>
      <td>4.518110</td>
      <td>-0.001168</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>510</th>
      <td>turkish</td>
      <td>3.300364</td>
      <td>-0.067426</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>597</th>
      <td>repeal</td>
      <td>3.547341</td>
      <td>-0.029784</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>668</th>
      <td>denies</td>
      <td>4.086952</td>
      <td>-0.074108</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>711</th>
      <td>spain</td>
      <td>3.610839</td>
      <td>-0.058848</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>845</th>
      <td>turkeys</td>
      <td>3.287574</td>
      <td>-0.043082</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>933</th>
      <td>comment</td>
      <td>3.082336</td>
      <td>-0.193297</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>950</th>
      <td>highlights</td>
      <td>4.261396</td>
      <td>-0.104503</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1006</th>
      <td>capital</td>
      <td>3.013810</td>
      <td>-0.048086</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1041</th>
      <td>bangladesh</td>
      <td>3.610831</td>
      <td>-0.116828</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1044</th>
      <td>zimbabwe</td>
      <td>3.767389</td>
      <td>-0.172499</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1097</th>
      <td>ireland</td>
      <td>3.526323</td>
      <td>-0.046192</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1137</th>
      <td>germanys</td>
      <td>4.382138</td>
      <td>-0.016014</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1196</th>
      <td>thursday</td>
      <td>3.290283</td>
      <td>-0.053666</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1230</th>
      <td>african</td>
      <td>4.120818</td>
      <td>-0.018743</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1247</th>
      <td>overhaul</td>
      <td>3.513037</td>
      <td>-0.075502</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1314</th>
      <td>crackdown</td>
      <td>3.310857</td>
      <td>-0.037923</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1413</th>
      <td>dispute</td>
      <td>3.956871</td>
      <td>-0.090974</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1450</th>
      <td>ministry</td>
      <td>4.036171</td>
      <td>-0.109830</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1579</th>
      <td>backing</td>
      <td>3.092978</td>
      <td>-0.069967</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1687</th>
      <td>monday</td>
      <td>3.315175</td>
      <td>-0.008043</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1732</th>
      <td>whether</td>
      <td>3.152854</td>
      <td>-0.160549</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1833</th>
      <td>queen</td>
      <td>3.389665</td>
      <td>-0.072860</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1842</th>
      <td>path</td>
      <td>3.891953</td>
      <td>-0.141704</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1846</th>
      <td>opening</td>
      <td>3.014429</td>
      <td>-0.035066</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1854</th>
      <td>kurdistan</td>
      <td>3.979890</td>
      <td>-0.055531</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1857</th>
      <td>indonesian</td>
      <td>3.204823</td>
      <td>-0.089595</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1898</th>
      <td>brazils</td>
      <td>3.093064</td>
      <td>-0.031818</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1970</th>
      <td>israels</td>
      <td>3.691689</td>
      <td>-0.062912</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1986</th>
      <td>firms</td>
      <td>3.748035</td>
      <td>-0.003477</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-3bc0e5d6-53d8-4afb-8319-1fc2b935d1c1')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-3bc0e5d6-53d8-4afb-8319-1fc2b935d1c1 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-3bc0e5d6-53d8-4afb-8319-1fc2b935d1c1');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>




### Bias

Whenever we create a machine learning model that might conceivably have impact on the thoughts or actions of human beings, we have a responsibility to understand the limitations and biases of that model. Biases can enter into machine learning models through several routes, including the data used as well as choices made by the modeler along the way. For example, in our case:

- Data: we used data from a popular news source.
- Modeler choice: we only used data corresponding to a certain subset of labels.

With these considerations in mind, let's see what kinds of words our model associates with female and male genders.


```python
feminine = ["she", "her", "woman"]
masculine = ["he", "him", "man"]

highlight_1 = ["strong", "powerful", "smart",     "thinking"]
highlight_2 = ["hot",    "sexy",     "beautiful", "shopping"]

def gender_mapper(x):
    if x in feminine:
        return 1
    elif x in masculine:
        return 4
    elif x in highlight_1:
        return 3
    elif x in highlight_2:
        return 2
    else:
        return 0

embedding_df["highlight"] = embedding_df["word"].apply(gender_mapper)
embedding_df["size"]      = np.array(1.0 + 50*(embedding_df["highlight"] > 0))
```


```python
import plotly.express as px 

fig = px.scatter(embedding_df, 
                 x = "x0", 
                 y = "x1", 
                 color = "highlight",
                 size = list(embedding_df["size"]),
                 size_max = 10,
                 hover_name = "word")

fig.show()
```

{% include Blog-Post-6-Plot8.html %}

Based on above plot, our text classification model's word embedding is not sexist.

Congratulations! You are now able to construct an extremely accurate model to classify authenticity of news article.
